{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff220c5",
   "metadata": {},
   "source": [
    "## LangChain - Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b461cc",
   "metadata": {},
   "source": [
    "Typical Prompt for RAG\n",
    "- Rules for out LLM (System prompt)\n",
    "- Context (Knowledge source)\n",
    "- Question (User prompt)\n",
    "- Answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8a7929",
   "metadata": {},
   "source": [
    "### Basic Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50eb2935",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57682795",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\"\n",
    "    Answer the user's query based on the context below. \n",
    "    If you cannot answer the question using the \n",
    "    provided information answer with \"I dont know\".\n",
    "\n",
    "    Context: {context}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b73b1951",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8347d89a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['context', 'query']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9fec01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\"\\n    Answer the user\\'s query based on the context below. \\n    If you cannot answer the question using the \\n    provided information answer with \"I dont know\".\\n\\n    Context: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44891ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More explicit way to define the role of the message\n",
    "prompt_template_2 = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e19cbcb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\"\\n    Answer the user\\'s query based on the context below. \\n    If you cannot answer the question using the \\n    provided information answer with \"I dont know\".\\n\\n    Context: {context}\\n'), additional_kwargs={}),\n",
       " HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['query'], input_types={}, partial_variables={}, template='{query}'), additional_kwargs={})]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that is the exactly same as prompt_template.messages\n",
    "prompt_template_2.messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896fb123",
   "metadata": {},
   "source": [
    "### Invoking LLM with Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca02747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a2295cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7685571b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069ce9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"\n",
    "    Aurelio AI is an AI company developing tooling for AI\n",
    "    engineers. Their focus is on language AI with the team having strong\n",
    "    expertise in building AI agents and a strong background in\n",
    "    information retrieval.\n",
    "\n",
    "    The company is behind several open source frameworks, most notably\n",
    "    Semantic Router and Semantic Chunkers. They also have an AI\n",
    "    Platform providing engineers with tooling to help them build with\n",
    "    AI. Finally, the team also provides development services to other\n",
    "    organizations to help them bring their AI tech to market.\n",
    "\n",
    "    Aurelio AI became LangChain Experts in September 2024 after a long\n",
    "    track record of delivering AI solutions built with the LangChain\n",
    "    ecosystem.\n",
    "\"\"\"\n",
    "\n",
    "query = \"What does Aurelio AI do?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f0a8169f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: We're using LangChain Expression Language (LCEL)\n",
    "# the '|' (aka pipe) connect our each component\n",
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb369b63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aurelio AI is an AI company that develops tooling for AI engineers, focusing on language AI. They have expertise in building AI agents and information retrieval. The company is known for several open source frameworks, including Semantic Router and Semantic Chunkers, and offers an AI Platform that provides engineers with tools to build with AI. Additionally, they provide development services to help other organizations bring their AI technology to market.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = pipeline.invoke({\"query\": query, \"context\": context})\n",
    "answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374bab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: It works without the dict\n",
    "pipeline_2 = (\n",
    "    {\n",
    "        \"query\": lambda x: x[\"query\"],\n",
    "        \"context\": lambda x: x[\"context\"]\n",
    "    }\n",
    "    | prompt_template_2\n",
    "    | llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d8569335",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aurelio AI is an AI company that develops tooling for AI engineers, focusing on language AI. They have expertise in building AI agents and information retrieval. The company is known for several open source frameworks, including Semantic Router and Semantic Chunkers, and offers an AI Platform that provides engineers with tools to build with AI. Additionally, they provide development services to help other organizations bring their AI technology to market.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_2 = pipeline_2.invoke({\"query\": query, \"context\": context})\n",
    "answer_2.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf6055a",
   "metadata": {},
   "source": [
    "### Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3989385e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e1a53c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"ai\", \"{output}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "863f6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\"input\": \"Here is query #1\", \"output\": \"Here is answer #1\"},\n",
    "    {\"input\": \"Here is query #2\", \"output\": \"Here is answer #2\"},\n",
    "    {\"input\": \"Here is query #3\", \"output\": \"Here is answer #3\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "235cfc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Here is query #1\n",
      "AI: Here is answer #1\n",
      "Human: Here is query #2\n",
      "AI: Here is answer #2\n",
      "Human: Here is query #3\n",
      "AI: Here is answer #3\n"
     ]
    }
   ],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "print(few_shot_prompt.format())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07fb9db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_system_prompt = \"\"\"\n",
    "    Answer the user's query based on the context below.\n",
    "    If you cannot answer the question using the\n",
    "    provided information answer with \"I don't know\".\n",
    "\n",
    "    Always answer in markdown format. When doing so please\n",
    "    provide headers, short summaries, follow with bullet\n",
    "    points, then conclude.\n",
    "\n",
    "    Context: {context}\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "53692947",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template.messages[0].prompt.template = new_system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1e565f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Overview of Aurelio AI\n",
      "\n",
      "Aurelio AI is an AI company that specializes in developing tools and services for AI engineers, particularly in the realm of language AI. \n",
      "\n",
      "## Key Focus Areas\n",
      "- **Language AI Development**: Expertise in building AI agents and information retrieval systems.\n",
      "- **Open Source Frameworks**: Creator of notable frameworks like Semantic Router and Semantic Chunkers.\n",
      "- **AI Platform**: Provides tooling for engineers to facilitate AI development.\n",
      "- **Development Services**: Offers assistance to organizations in bringing their AI technologies to market.\n",
      "\n",
      "## Achievements\n",
      "- Became LangChain Experts in September 2024, showcasing their proficiency in the LangChain ecosystem.\n",
      "\n",
      "In conclusion, Aurelio AI is dedicated to empowering AI engineers through innovative tools, frameworks, and development services in the language AI space.\n"
     ]
    }
   ],
   "source": [
    "out = pipeline.invoke({\"query\": query, \"context\": context}).content\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cece26cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Can you explain gravity?\",\n",
    "        \"output\": (\n",
    "            \"## Gravity\\n\\n\"\n",
    "            \"Gravity is one of the fundamental forces in the universe.\\n\\n\"\n",
    "            \"### Discovery\\n\\n\"\n",
    "            \"* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n\"\n",
    "            \"* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n\"\n",
    "            \"### In General Relativity\\n\\n\"\n",
    "            \"* Gravity is described as the curvature of spacetime.\\n\"\n",
    "            \"* The more massive an object is, the more it curves spacetime.\\n\"\n",
    "            \"* This curvature is what causes objects to fall towards each other.\\n\\n\"\n",
    "            \"### Gravitons\\n\\n\"\n",
    "            \"* Gravitons are hypothetical particles that mediate the force of gravity.\\n\"\n",
    "            \"* They have not yet been detected.\\n\\n\"\n",
    "            \"**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n\"\n",
    "        )\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"What is the capital of France?\",\n",
    "        \"output\": (\n",
    "            \"## France\\n\\n\"\n",
    "            \"The capital of France is Paris.\\n\\n\"\n",
    "            \"### Origins\\n\\n\"\n",
    "            \"* The name Paris comes from the Latin word \\\"Parisini\\\" which referred to a Celtic people living in the area.\\n\"\n",
    "            \"* The Romans named the city Lutetia, which means \\\"the place where the river turns\\\".\\n\"\n",
    "            \"* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n\"\n",
    "            \"**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world's greatest cultural and economic centres.\\n\\n\"\n",
    "        )\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4df6ce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FewShotChatMessagePromptTemplate(examples=[{'input': 'Can you explain gravity?', 'output': '## Gravity\\n\\nGravity is one of the fundamental forces in the universe.\\n\\n### Discovery\\n\\n* Gravity was first discovered by Sir Isaac Newton in the late 17th century.\\n* It was said that Newton theorized about gravity after seeing an apple fall from a tree.\\n\\n### In General Relativity\\n\\n* Gravity is described as the curvature of spacetime.\\n* The more massive an object is, the more it curves spacetime.\\n* This curvature is what causes objects to fall towards each other.\\n\\n### Gravitons\\n\\n* Gravitons are hypothetical particles that mediate the force of gravity.\\n* They have not yet been detected.\\n\\n**To conclude**, Gravity is a fascinating topic and has been studied extensively since the time of Newton.\\n\\n'}, {'input': 'What is the capital of France?', 'output': '## France\\n\\nThe capital of France is Paris.\\n\\n### Origins\\n\\n* The name Paris comes from the Latin word \"Parisini\" which referred to a Celtic people living in the area.\\n* The Romans named the city Lutetia, which means \"the place where the river turns\".\\n* The city was renamed Paris in the 3rd century BC by the Celtic-speaking Parisii tribe.\\n\\n**To conclude**, Paris is highly regarded as one of the most beautiful cities in the world and is one of the world\\'s greatest cultural and economic centres.\\n\\n'}], input_variables=[], input_types={}, partial_variables={}, example_prompt=ChatPromptTemplate(input_variables=['input', 'output'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={}), AIMessagePromptTemplate(prompt=PromptTemplate(input_variables=['output'], input_types={}, partial_variables={}, template='{output}'), additional_kwargs={})]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=example_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f80fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_3 = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", new_system_prompt),\n",
    "    few_shot_prompt,\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "bdd8586d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_3 = prompt_template_3 | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "569b71e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_3 = pipeline_3.invoke({\"query\": query, \"context\": context})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6f5183af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Aurelio AI Overview\n",
      "\n",
      "Aurelio AI is an AI company focused on developing tools and services for AI engineers, particularly in the realm of language AI.\n",
      "\n",
      "### Key Areas of Focus\n",
      "\n",
      "- **Language AI**: Specializes in creating AI solutions that understand and generate human language.\n",
      "- **AI Agents**: Expertise in building intelligent agents that can perform tasks autonomously.\n",
      "- **Information Retrieval**: Strong background in retrieving and processing information effectively.\n",
      "\n",
      "### Products and Services\n",
      "\n",
      "- **Open Source Frameworks**: \n",
      "  - **Semantic Router**: A framework for managing semantic tasks.\n",
      "  - **Semantic Chunkers**: A tool for breaking down and processing language data.\n",
      "  \n",
      "- **AI Platform**: \n",
      "  - Provides engineers with tools to facilitate AI development.\n",
      "  \n",
      "- **Development Services**: \n",
      "  - Offers assistance to organizations in bringing their AI technologies to market.\n",
      "\n",
      "### Recognition\n",
      "\n",
      "- Became **LangChain Experts** in September 2024, showcasing their proficiency in the LangChain ecosystem.\n",
      "\n",
      "**To conclude**, Aurelio AI is dedicated to empowering AI engineers with innovative tools and services, while also contributing to the open-source community.\n"
     ]
    }
   ],
   "source": [
    "print(answer_3.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe454012",
   "metadata": {},
   "source": [
    "### Chain of Thought prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6f0c6bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cot_system_prompt = \"\"\"\n",
    "    Be a helpful assistant and answer the user's question.\n",
    "    You MUST answer the question directly without any other\n",
    "    text or explanation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "29f26b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", no_cot_system_prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3a6ac9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = (\n",
    "    \"How many keystrokes are needed to type the numbers 1 to 500?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "080a9b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cot_pipeline = no_cot_prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ad157376",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cot_result = no_cot_pipeline.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c532621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of keystrokes needed to type the numbers 1 to 500 is 1,511.\n"
     ]
    }
   ],
   "source": [
    "print(no_cot_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f4b2cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_system_prompt = \"\"\"\n",
    "    Be a helpful assistant and answer the user's question. \n",
    "\n",
    "    To answer que question you must:\n",
    "    - List systematically and in precise detail all subproblem\n",
    "    that need to be solved to answer the question.\n",
    "    - Solve each sub problem INDIVIDUALLY and in sequence.\n",
    "    - Finally, use everything you have worked through to \n",
    "    provide the final answer. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b7b3517",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", cot_system_prompt),\n",
    "    (\"user\", \"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0fb72b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_pipeline = cot_prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e33189f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_result = cot_pipeline.invoke({\"query\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a7b70386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To determine how many keystrokes are needed to type the numbers from 1 to 500, we can break this problem down into several subproblems:\n",
      "\n",
      "1. **Count the numbers in each range**:\n",
      "   - Count the numbers from 1 to 9 (1-digit numbers).\n",
      "   - Count the numbers from 10 to 99 (2-digit numbers).\n",
      "   - Count the numbers from 100 to 499 (3-digit numbers).\n",
      "   - Count the number 500 (a 3-digit number).\n",
      "\n",
      "2. **Calculate the total number of keystrokes for each range**:\n",
      "   - Calculate the total keystrokes for 1-digit numbers.\n",
      "   - Calculate the total keystrokes for 2-digit numbers.\n",
      "   - Calculate the total keystrokes for 3-digit numbers.\n",
      "\n",
      "3. **Sum the total keystrokes from all ranges**.\n",
      "\n",
      "Now, let's solve each subproblem step by step.\n",
      "\n",
      "### Subproblem 1: Count the numbers in each range\n",
      "\n",
      "1. **1-digit numbers (1 to 9)**:\n",
      "   - There are 9 numbers (1, 2, 3, 4, 5, 6, 7, 8, 9).\n",
      "\n",
      "2. **2-digit numbers (10 to 99)**:\n",
      "   - There are 90 numbers (from 10 to 99 inclusive).\n",
      "\n",
      "3. **3-digit numbers (100 to 499)**:\n",
      "   - There are 400 numbers (from 100 to 499 inclusive).\n",
      "\n",
      "4. **The number 500**:\n",
      "   - There is 1 number (500).\n",
      "\n",
      "### Subproblem 2: Calculate the total number of keystrokes for each range\n",
      "\n",
      "1. **1-digit numbers**:\n",
      "   - Each number has 1 digit.\n",
      "   - Total keystrokes = 9 numbers × 1 keystroke = 9 keystrokes.\n",
      "\n",
      "2. **2-digit numbers**:\n",
      "   - Each number has 2 digits.\n",
      "   - Total keystrokes = 90 numbers × 2 keystrokes = 180 keystrokes.\n",
      "\n",
      "3. **3-digit numbers (100 to 499)**:\n",
      "   - Each number has 3 digits.\n",
      "   - Total keystrokes = 400 numbers × 3 keystrokes = 1200 keystrokes.\n",
      "\n",
      "4. **The number 500**:\n",
      "   - The number 500 has 3 digits.\n",
      "   - Total keystrokes = 1 number × 3 keystrokes = 3 keystrokes.\n",
      "\n",
      "### Subproblem 3: Sum the total keystrokes from all ranges\n",
      "\n",
      "Now, we sum the total keystrokes from all the ranges:\n",
      "\n",
      "- Total keystrokes from 1-digit numbers: 9\n",
      "- Total keystrokes from 2-digit numbers: 180\n",
      "- Total keystrokes from 3-digit numbers (100 to 499): 1200\n",
      "- Total keystrokes from the number 500: 3\n",
      "\n",
      "Total keystrokes = 9 + 180 + 1200 + 3 = 1392\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "The total number of keystrokes needed to type the numbers from 1 to 500 is **1392**.\n"
     ]
    }
   ],
   "source": [
    "print(cot_result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241be339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
