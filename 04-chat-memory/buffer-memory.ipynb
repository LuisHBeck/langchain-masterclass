{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "837d1a66",
   "metadata": {},
   "source": [
    "## LangChain Chat Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d522c26",
   "metadata": {},
   "source": [
    "- ConversationBufferMemory \n",
    "    - It's like a list with all the messages\n",
    "- ConversationBufferWindowMemory\n",
    "    - Quite similar to the above one, but returns just only a chunk of the list\n",
    "- ConversationSummaryMemory\n",
    "    - Instead of storing the complete messages, it stores only a summary of the conversation\n",
    "- ConversationSummaryBufferMemory\n",
    "    - Combination between ConversationSummaryMemory and ConversationBufferWindowMemory\n",
    "    You get a summary of the conversation + Xk of recent tokens stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdd6192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa606ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.0, model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b17097",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory - DEPRECATED WAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9f160c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7be5124",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buffer_memory = ConversationBufferMemory(return_messages=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a50c73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_buffer_memory.save_context(\n",
    "    {\"input\": \"Hi, my name is Luis!\"}, # user message\n",
    "    {\"output\": \"Hey Luis, what's up? I'm an AI model called Zeta.\"} # AI response\n",
    ")\n",
    "conversation_buffer_memory.save_context(\n",
    "    {\"input\": \"I'm researching the different types of conversational memory.\"},  # user message\n",
    "    {\"output\": \"That's interesting, what are some examples?\"}  # AI response\n",
    ")\n",
    "conversation_buffer_memory.save_context(\n",
    "    {\"input\": \"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\"},  # user message\n",
    "    {\"output\": \"That's interesting, what's the difference?\"}  # AI response\n",
    ")\n",
    "conversation_buffer_memory.save_context(\n",
    "    {\"input\": \"Buffer memory just stores the entire conversation, right?\"},  # user message\n",
    "    {\"output\": \"That makes sense, what about ConversationBufferWindowMemory?\"}  # AI response\n",
    ")\n",
    "conversation_buffer_memory.save_context(\n",
    "    {\"input\": \"Buffer window memory stores the last k messages, dropping the rest.\"},  # user message\n",
    "    {\"output\": \"Very cool!\"}  # AI response\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b4fb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, my name is Luis!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey Luis, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_buffer_memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861b2acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='Hi, my name is James', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey James, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You also can do in this way\n",
    "conversation_buffer_memory_2 = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "conversation_buffer_memory_2.chat_memory.add_user_message(\"Hi, my name is James\")\n",
    "conversation_buffer_memory_2.chat_memory.add_ai_message(\"Hey James, what's up? I'm an AI model called Zeta.\")\n",
    "conversation_buffer_memory_2.chat_memory.add_user_message(\"I'm researching the different types of conversational memory.\")\n",
    "conversation_buffer_memory_2.chat_memory.add_ai_message(\"That's interesting, what are some examples?\")\n",
    "conversation_buffer_memory_2.chat_memory.add_user_message(\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\")\n",
    "conversation_buffer_memory_2.chat_memory.add_ai_message(\"That's interesting, what's the difference?\")\n",
    "conversation_buffer_memory_2.chat_memory.add_user_message(\"Buffer memory just stores the entire conversation, right?\")\n",
    "conversation_buffer_memory_2.chat_memory.add_ai_message(\"That makes sense, what about ConversationBufferWindowMemory?\")\n",
    "conversation_buffer_memory_2.chat_memory.add_user_message(\"Buffer window memory stores the last k messages, dropping the rest.\")\n",
    "conversation_buffer_memory_2.chat_memory.add_ai_message(\"Very cool!\")\n",
    "\n",
    "# Same result as above\n",
    "conversation_buffer_memory_2.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32acce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a79db761",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luis\\AppData\\Local\\Temp\\ipykernel_16872\\1490735486.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  chain = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "chain = ConversationChain(\n",
    "    llm=llm,\n",
    "    memory=conversation_buffer_memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec440fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "[HumanMessage(content='Hi, my name is Luis!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hey Luis, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}), HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}), AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}), HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}), AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Luis!', additional_kwargs={}, response_metadata={})]\n",
      "Human: What's my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': \"What's my name?\",\n",
       " 'history': [HumanMessage(content='Hi, my name is Luis!', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"Hey Luis, what's up? I'm an AI model called Zeta.\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I'm researching the different types of conversational memory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what are some examples?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"I've been looking at ConversationBufferMemory and ConversationBufferWindowMemory.\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content=\"That's interesting, what's the difference?\", additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer memory just stores the entire conversation, right?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='That makes sense, what about ConversationBufferWindowMemory?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='Buffer window memory stores the last k messages, dropping the rest.', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Very cool!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Luis!', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Luis!', additional_kwargs={}, response_metadata={})],\n",
       " 'response': 'Your name is Luis!'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"What's my name?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f0747d",
   "metadata": {},
   "source": [
    "### ConversationBufferMemory - Newest version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "53f2c5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import (\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    ChatPromptTemplate\n",
    ")\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "571760e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant called Zeta.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cf9acc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\"{query}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1af5fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49af60ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_map = {}\n",
    "def get_chat_history(session_id: str) -> InMemoryChatMessageHistory:\n",
    "    if session_id not in chat_map:\n",
    "        # if session ID doesn't exists, create new chat history\n",
    "        chat_map[session_id] = InMemoryChatMessageHistory()\n",
    "    return chat_map[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a874b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_with_history = RunnableWithMessageHistory(\n",
    "    pipeline,\n",
    "    get_session_history=get_chat_history,\n",
    "    input_messages_key=\"query\",\n",
    "    history_messages_key=\"history\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7eaf6abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hi Luis! How can I assist you today?'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"Hi, my name is Luis\"},\n",
    "    config={\"session_id\": \"id_1234\"}\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f385bb24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Luis. Is there anything specific you would like to talk about?'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_with_history.invoke(\n",
    "    {\"query\": \"What's my name?\"},\n",
    "    config={\"session_id\": \"id_1234\"}\n",
    ").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580669fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
