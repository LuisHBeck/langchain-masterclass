{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3302fc74",
   "metadata": {},
   "source": [
    "## LangChain - Query translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df3cfcd7",
   "metadata": {},
   "source": [
    "### Multi-Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2670f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain.load import dumps, loads\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1864880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INDEXING ##\n",
    "\n",
    "# Load blog\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "blog_docs = loader.load()\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=300,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "# Make splits \n",
    "splits = text_splitter.split_documents(blog_docs)\n",
    "\n",
    "# embedding\n",
    "embedding = AzureOpenAIEmbeddings(\n",
    "    model=\"text-embedding-3-large\"\n",
    ")\n",
    "\n",
    "# Index\n",
    "vector_store = Chroma.from_documents(documents=splits, embedding=embedding)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c09403",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-12-01-preview\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354d04f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt ##\n",
    "\n",
    "# Multi Query: Different Perspectives\n",
    "template = \"\"\"\n",
    "    You are an AI language model assistant. Your task is to generate five different\n",
    "    versions of the given user question to retrieve relevant documents from a vector\n",
    "    database. By generating multiple perspectives on the user question, your goal is\n",
    "    to help the user overcome some of the limitations of the distance-based similarity\n",
    "    search. Provide these alternative questions separated by newlines.\n",
    "    Original question: {question}\n",
    "\"\"\"\n",
    "prompt_perspective = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "generate_queries = (\n",
    "    prompt_perspective\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcac09e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BEU7CA\\AppData\\Local\\Temp\\ipykernel_12248\\1830023186.py:7: LangChainBetaWarning: The function `loads` is in beta. It is actively being worked on, so the API may change.\n",
      "  return [loads(doc) for doc in unique_docs]\n"
     ]
    }
   ],
   "source": [
    "def get_unique_union(documents: list[list]):\n",
    "    \"\"\"Unique union of retrieved docs\"\"\"\n",
    "    # Flatten list of lists, and convert each Document to string\n",
    "    flatten_docs = [dumps(doc) for sublist in documents for doc in sublist]\n",
    "    # Get unique document\n",
    "    unique_docs = list(set(flatten_docs))\n",
    "    return [loads(doc) for doc in unique_docs]\n",
    "\n",
    "# Retrieve\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "retrieval_chain = generate_queries | retriever.map() | get_unique_union\n",
    "docs = retrieval_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "260efe2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c383d177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, more manageable subgoals to enhance efficiency in handling intricate problems. This process can be facilitated by techniques such as Chain of Thought (CoT) prompting, which encourages the model to “think step by step.” CoT helps in transforming a large task into a series of simpler steps, thereby illuminating the model's thinking process.\\n\\nAdditionally, the Tree of Thoughts approach extends CoT by allowing the exploration of multiple reasoning possibilities at each step. It involves decomposing the problem into various thought steps and generating multiple thoughts per step, forming a tree structure that can be traversed using search methods like breadth-first search (BFS) or depth-first search (DFS).\\n\\nTask decomposition can be achieved through various means, including:\\n1. Simple prompting, such as asking for the steps needed to complete a task or identifying subgoals.\\n2. Task-specific instructions tailored to particular activities (e.g., creating an outline for a story).\\n3. Input from human users.\\n\\nOverall, task decomposition is crucial for LLM agents as it aids in organizing and simplifying complicated tasks, enabling better planning and execution.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "template = \"\"\"\"\n",
    "    Answer the following question based on this context:\n",
    "\n",
    "    {context}\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\n",
    "        \"context\": retrieval_chain,\n",
    "        \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | prompt\n",
    "    | llm \n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc1c11a",
   "metadata": {},
   "source": [
    "### RAG Fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d7d156",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = AzureChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_version=\"2024-12-01-preview\",\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b8cdefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG-Fusion: Related\n",
    "fusion_template = \"\"\"\n",
    "    You are a helpful assistant that generates multiple search queries based \n",
    "    on a single input query. \\n Generates a multiple search queries related to: \\n\n",
    "    {question}\n",
    "    Output (4 queries):\n",
    "\"\"\"\n",
    "prompt_rag_fusion = ChatPromptTemplate.from_template(fusion_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a896b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_queries_fusion = (\n",
    "    prompt_rag_fusion\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73f48bd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def reciprocal_rank_fusion(results: list[list], k=60):\n",
    "    \"\"\"\n",
    "    Reciprocal_rank_fusion that takes multiple list of ranked\n",
    "    documents and an optional parameter k used in the RRF formula\n",
    "    \"\"\"\n",
    "    # Initialize a dictionary to hold fused scores for each unique document\n",
    "    fused_scores = {}\n",
    "\n",
    "    # Iterate through each list of ranked documents\n",
    "    for docs in results:\n",
    "        # Iterate through each document in the list, with its rank (position in the list)\n",
    "        for rank, doc in enumerate(docs):\n",
    "            # Convert the document to a string format to use as a key (assumes documents can be serialized to JSON)\n",
    "            doc_str = dumps(doc)\n",
    "            # If the document is not yet in the fused_scores dictionary, add it with an initial score of 0\n",
    "            if doc_str not in fused_scores:\n",
    "                fused_scores[doc_str] = 0\n",
    "            # Retrieve the current score of the document, if any\n",
    "            previous_score = fused_scores[doc_str]\n",
    "            # Update the score of the document using the RRF formula 1 / (rank + k)\n",
    "            fused_scores[doc_str] += 1 / (rank + k)\n",
    "\n",
    "    # Sort the documents based on their fused scores in descending order to get the final ranked results\n",
    "    reranked_results = [\n",
    "        (loads(doc), score)\n",
    "        for doc, score in sorted(fused_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    ]\n",
    "\n",
    "    # Return the reranked results as a list of tuples, each containing the document and its fused score\n",
    "    return reranked_results\n",
    "\n",
    "retrieval_chain_rag_fusion = generate_queries_fusion | retriever.map() | reciprocal_rank_fusion\n",
    "docs = retrieval_chain_rag_fusion.invoke({\"question\": question})\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58d9ab8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enables the agent to handle intricate tasks more efficiently. There are several methods for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" allowing it to decompose difficult tasks into simpler steps, thereby enhancing its performance.\\n\\n2. **Tree of Thoughts**: This approach extends CoT by exploring multiple reasoning possibilities at each step, creating a tree structure of thoughts. It decomposes the problem into multiple thought steps and generates various thoughts per step, which can be evaluated through methods like breadth-first search (BFS) or depth-first search (DFS).\\n\\n3. **Prompting Techniques**: Task decomposition can be achieved through simple prompts, such as asking for the steps to achieve a goal or identifying subgoals.\\n\\n4. **Task-Specific Instructions**: Providing specific instructions tailored to the task, such as asking for a story outline when writing a novel.\\n\\n5. **Human Inputs**: Involving human guidance to assist in breaking down tasks.\\n\\nOverall, task decomposition is a crucial component that allows LLM agents to manage and execute complex tasks more effectively.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"\"\"\"\n",
    "    Answer the following question based on this context:\n",
    "\n",
    "    {context}\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "final_rag_chain = (\n",
    "    {\n",
    "        \"context\": retrieval_chain_rag_fusion,\n",
    "        \"question\": itemgetter(\"question\") \n",
    "    }\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb8100",
   "metadata": {},
   "source": [
    "### Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9876de6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_decomposition = \"\"\"\n",
    "    You are a helpful assistant that generates multiple sub-questions related\n",
    "    to an input question. \\n The goal is to break down the input a set of sub-problems /\n",
    "    sub-questions that can be answered in isolation. \\n Generate multiple search queries\n",
    "    related to: {question}.\n",
    "    Output (3 queries): \n",
    "\"\"\"\n",
    "prompt_decomposition = ChatPromptTemplate.from_template(template_decomposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b58299b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_query_decomposition = (\n",
    "    prompt_decomposition\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    "    | (lambda x: x.split(\"\\n\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ddd011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are the main components of an LLM-powered agent system?\"\n",
    "questions = generate_query_decomposition.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5195df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1. What are the key components of a large language model (LLM) architecture?',\n",
       " '2. How do LLMs integrate with other systems in an agent-based architecture?',\n",
       " '3. What role does data preprocessing play in the performance of an LLM-powered agent system?']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17b68353",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\"\n",
    "    Here is the question you need to answer:\n",
    "    \\n --- \\n {question} \\n --- \\n\n",
    "\n",
    "    Here is any available background question + answer pairs:\n",
    "    \\n --- \\n {q_a_pairs} \\n --- \\n\n",
    "\n",
    "    Here is the additional context relevant to the question:\n",
    "    \\n --- \\n {context} \\n --- \\n\n",
    "\n",
    "    Use the above context and any background question + answer pairs to answer\n",
    "    the question: \\n {question}.\n",
    "\"\"\"\n",
    "decomposition_prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f221abb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_qa_pair(question, answer):\n",
    "    \"\"\"Format Q and A pair\"\"\"\n",
    "    formatted_str = \"\"\n",
    "    formatted_str += f\"Question: {question}\\nAnswer: {answer}\\n\\n\"\n",
    "    return formatted_str.strip()\n",
    "\n",
    "q_a_pairs = \"\"\n",
    "for q in questions:\n",
    "    rag_chain_decomposition = (\n",
    "        {\n",
    "            \"context\": itemgetter(\"question\") | retriever,\n",
    "            \"question\": itemgetter(\"question\"),\n",
    "            \"q_a_pairs\": itemgetter(\"q_a_pairs\")\n",
    "        }\n",
    "        | decomposition_prompt\n",
    "        | llm\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    answer = rag_chain_decomposition.invoke({\"question\": q, \"q_a_pairs\": q_a_pairs})\n",
    "    q_a_pair = format_qa_pair(q, answer)\n",
    "    q_a_pairs = q_a_pairs + \"\\n --- \\n\" + q_a_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "391dd5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Data preprocessing plays a crucial role in the performance of an LLM-powered agent system by ensuring that the input data is clean, relevant, and structured in a way that maximizes the model's ability to understand and generate appropriate responses. Here are several key aspects of how data preprocessing impacts the performance of such systems:\\n\\n1. **Quality of Input Data**: Preprocessing helps filter out noise and irrelevant information from the input data. High-quality, well-structured data allows the LLM to learn more effectively from the training phase and perform better during inference. This is particularly important in agent systems where the LLM needs to interact with various external components and APIs.\\n\\n2. **Normalization and Standardization**: Preprocessing often involves normalizing and standardizing data formats, which helps the LLM interpret inputs consistently. This is essential for maintaining reliability in the natural language interface, as inconsistencies in data can lead to formatting errors or misinterpretations by the model.\\n\\n3. **Context Management**: Given the finite context length of LLMs, preprocessing can help manage the amount of historical information included in the input. By selecting the most relevant context and summarizing or condensing information, preprocessing ensures that the LLM can focus on the most pertinent details, enhancing its ability to generate coherent and contextually appropriate responses.\\n\\n4. **Task Decomposition**: Effective preprocessing can assist in breaking down complex tasks into smaller, manageable components. This aligns with the LLM's capability to decompose tasks into subgoals, facilitating more efficient problem-solving and planning within the agent system.\\n\\n5. **Error Reduction**: By preprocessing data to eliminate inconsistencies and errors, the likelihood of the LLM generating incorrect or nonsensical outputs is reduced. This is particularly important in agent systems where reliability is critical, as errors can lead to significant issues in task execution.\\n\\n6. **Training Efficiency**: Preprocessed data can improve the efficiency of the training process by providing the LLM with clear and relevant examples. This can lead to faster convergence during training and better generalization to unseen data, ultimately enhancing the agent's performance in real-world applications.\\n\\n7. **Facilitating Reflection and Refinement**: Preprocessing can also support the self-reflection and refinement processes of the LLM. By providing structured feedback and clear examples of past actions, the model can learn from its mistakes more effectively, leading to improved future performance.\\n\\nIn summary, data preprocessing is a foundational step that significantly influences the effectiveness and reliability of LLM-powered agent systems. By ensuring high-quality, relevant, and well-structured input data, preprocessing enhances the model's ability to understand context, generate accurate responses, and perform complex tasks efficiently.\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6722c7b",
   "metadata": {},
   "source": [
    "### Step-back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ccb3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import FewShotChatMessagePromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75ce9210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Show Examples\n",
    "examples = [\n",
    "    {\n",
    "        \"input\": \"Could the members of The Police perform lawful arrests?\",\n",
    "        \"output\": \"what cna the member of The Police do?\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Jan Sindel's was born in what country?\",\n",
    "        \"output\": \"what is Jan Sindel's personal history?\"\n",
    "    },\n",
    "]\n",
    "\n",
    "examples_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\"),\n",
    "        (\"ai\", \"{output}\"),\n",
    "    ]\n",
    ")\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt=examples_prompt,\n",
    "    examples=examples\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are an expert world knowledge. Your task is to step back and paraphrase a question to more generic step-back question, which is easier to answer. Here a few examples: \"\n",
    "        ),\n",
    "        few_shot_prompt,\n",
    "        (\"user\", \"{question}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7017c8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What does task decomposition mean in the context of agents?'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_queries_step_back = prompt | llm | StrOutputParser()\n",
    "question = \"What is task decomposition for LLM agents?\"\n",
    "generate_queries_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c01ad53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "635bceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents refers to the process of breaking down complex tasks into smaller, more manageable subgoals or steps. This approach enhances the agent\\'s ability to handle intricate problems by allowing it to focus on simpler components, thereby improving efficiency and effectiveness in task execution.\\n\\nThere are several techniques and methodologies for task decomposition in LLM agents:\\n\\n1. **Chain of Thought (CoT)**: This standard prompting technique encourages the model to \"think step by step.\" By doing so, it utilizes more computational resources at test time to decompose difficult tasks into simpler, sequential steps. This method not only aids in task management but also provides insights into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: An extension of CoT, this approach explores multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts for each step, creating a tree structure. The search process can be conducted using breadth-first search (BFS) or depth-first search (DFS), with each state evaluated by a classifier or through majority voting.\\n\\n3. **Prompting Techniques**: Task decomposition can be achieved through simple prompting, such as asking the LLM to list the steps for a specific task or to identify subgoals. Additionally, task-specific instructions can guide the model, or human inputs can be utilized to define the decomposition process.\\n\\n4. **LLM+P Approach**: This method involves using an external classical planner for long-horizon planning. The LLM translates the problem into a Planning Domain Definition Language (PDDL) format, requests a classical planner to generate a plan, and then translates that plan back into natural language. This approach is particularly useful in domains where domain-specific PDDL and suitable planners are available.\\n\\nOverall, task decomposition is a critical component of LLM-powered autonomous agents, enabling them to tackle complex tasks more effectively by breaking them down into simpler, actionable parts.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_prompt_template = \"\"\"\n",
    "    You are an expert of world knowledge. I am going to ask you a question.\n",
    "    Your response should be comprehensive and not contradicted with the following \n",
    "    context if they are relevant. Otherwise, ignore them if they are not relevant.\n",
    "\n",
    "    # {normal_context}\n",
    "    # {step_back_context}\n",
    "\n",
    "    # Original question: {question}\n",
    "    # Answer: \n",
    "\"\"\"\n",
    "response_prompt = ChatPromptTemplate.from_template(response_prompt_template)\n",
    "\n",
    "chain_step_back = (\n",
    "    {\n",
    "        # retrieve context using the normal question\n",
    "        \"normal_context\": RunnableLambda(lambda x: x[\"question\"]) | retriever,\n",
    "        # retrieve context using the step-back question\n",
    "        \"step_back_context\": generate_queries_step_back | retriever,\n",
    "        # pass on the question\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "    }\n",
    "    | response_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain_step_back.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b62fff5",
   "metadata": {},
   "source": [
    "### HyDE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "724ac38b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"**Task Decomposition for LLM Agents: A Comprehensive Overview**\\n\\nTask decomposition is a critical concept in the realm of Large Language Model (LLM) agents, referring to the systematic breakdown of complex tasks into smaller, more manageable sub-tasks. This process is essential for enhancing the efficiency and effectiveness of LLMs in performing intricate operations that require multi-step reasoning and decision-making.\\n\\nIn the context of LLM agents, task decomposition involves several key steps. First, the overarching task is analyzed to identify its constituent components. This may include recognizing distinct phases of the task, such as data gathering, processing, analysis, and output generation. By segmenting the task, LLM agents can leverage their capabilities to address each sub-task individually, thereby reducing cognitive load and improving accuracy.\\n\\nMoreover, task decomposition facilitates parallel processing, where multiple sub-tasks can be executed simultaneously or in a more streamlined sequence. This is particularly advantageous in scenarios where time efficiency is paramount, as it allows LLM agents to optimize their performance by focusing on specific aspects of a task without being overwhelmed by its complexity.\\n\\nAdditionally, task decomposition enhances the interpretability of LLM outputs. By structuring the problem into smaller parts, it becomes easier to trace the reasoning behind the agent's decisions and conclusions. This transparency is crucial for applications in sensitive domains such as healthcare, finance, and legal systems, where understanding the rationale behind automated decisions is essential for trust and accountability.\\n\\nFurthermore, task decomposition can be informed by various methodologies, including hierarchical task networks (HTNs) and goal-oriented planning. These frameworks provide a structured approach to decompose tasks based on predefined goals and constraints, allowing LLM agents to navigate complex problem spaces more effectively.\\n\\nIn conclusion, task decomposition is a fundamental strategy for enhancing the capabilities of LLM agents. By breaking down complex tasks into simpler sub-tasks, LLMs can improve their performance, efficiency, and interpretability, ultimately leading to more robust and reliable applications across diverse fields. As research in this area continues to evolve, further advancements in task decomposition techniques are expected to unlock new potentials for LLM agents in tackling increasingly sophisticated challenges.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# HyDE document generation\n",
    "template_hyde = \"\"\"\n",
    "    Please write a scientific paper passage to answer the question\n",
    "    Question: {question}\n",
    "    Passage: \n",
    "\"\"\"\n",
    "prompt_hyde = ChatPromptTemplate.from_template(template_hyde)\n",
    "\n",
    "generate_docs_for_retrieval_hyde = (\n",
    "    prompt_hyde | llm | StrOutputParser()\n",
    ")\n",
    "\n",
    "# run\n",
    "question = \"What is task decomposition for LLM Agents?\"\n",
    "generate_docs_for_retrieval_hyde.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "af65e747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Component One: Planning#\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\\nTask Decomposition#\\nChain of thought (CoT; Wei et al. 2022) has become a standard prompting technique for enhancing model performance on complex tasks. The model is instructed to “think step by step” to utilize more test-time computation to decompose hard tasks into smaller and simpler steps. CoT transforms big tasks into multiple manageable tasks and shed lights into an interpretation of the model’s thinking process.\\nTree of Thoughts (Yao et al. 2023) extends CoT by exploring multiple reasoning possibilities at each step. It first decomposes the problem into multiple thought steps and generates multiple thoughts per step, creating a tree structure. The search process can be BFS (breadth-first search) or DFS (depth-first search) with each state evaluated by a classifier (via a prompt) or majority vote.\\nTask decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outline.\" for writing a novel, or (3) with human inputs.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Finite context length: The restricted context capacity limits the inclusion of historical information, detailed instructions, API call context, and responses. The design of the system has to work with this limited communication bandwidth, while mechanisms like self-reflection to learn from past mistakes would benefit a lot from long or infinite context windows. Although vector stores and retrieval can provide access to a larger knowledge pool, their representation power is not as powerful as full attention.\\n\\n\\nChallenges in long-term planning and task decomposition: Planning over a lengthy history and effectively exploring the solution space remain challenging. LLMs struggle to adjust plans when faced with unexpected errors, making them less robust compared to humans who learn from trial and error.\\n\\n\\nReliability of natural language interface: Current agent system relies on natural language as an interface between LLMs and external components such as memory and tools. However, the reliability of model outputs is questionable, as LLMs may make formatting errors and occasionally exhibit rebellious behavior (e.g. refuse to follow an instruction). Consequently, much of the agent demo code focuses on parsing model output.\\n\\n\\nCitation#\\nCited as:\\n\\nWeng, Lilian. (Jun 2023). “LLM-powered Autonomous Agents”. Lil’Log. https://lilianweng.github.io/posts/2023-06-23-agent/.'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='LLM Powered Autonomous Agents\\n    \\nDate: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\\n\\n\\nBuilding agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview#\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory'),\n",
       " Document(metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}, page_content='Another quite distinct approach, LLM+P (Liu et al. 2023), involves relying on an external classical planner to do long-horizon planning. This approach utilizes the Planning Domain Definition Language (PDDL) as an intermediate interface to describe the planning problem. In this process, LLM (1) translates the problem into “Problem PDDL”, then (2) requests a classical planner to generate a PDDL plan based on an existing “Domain PDDL”, and finally (3) translates the PDDL plan back into natural language. Essentially, the planning step is outsourced to an external tool, assuming the availability of domain-specific PDDL and a suitable planner which is common in certain robotic setups but not in many other domains.\\nSelf-Reflection#\\nSelf-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in real-world tasks where trial and error are inevitable.\\nReAct (Yao et al. 2023) integrates reasoning and acting within LLM by extending the action space to be a combination of task-specific discrete actions and the language space. The former enables LLM to interact with the environment (e.g. use Wikipedia search API), while the latter prompting LLM to generate reasoning traces in natural language.\\nThe ReAct prompt template incorporates explicit steps for LLM to think, roughly formatted as:')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain_hyde = generate_docs_for_retrieval_hyde | retriever\n",
    "retrieved_docs_hyde = retrieval_chain_hyde.invoke({\"question\": question})\n",
    "retrieved_docs_hyde"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0eb296e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Task decomposition for LLM (large language model) agents involves breaking down complex tasks into smaller, manageable subgoals. This process enhances the agent\\'s ability to handle complicated tasks by allowing it to plan ahead and think step by step. \\n\\nThere are several methods for task decomposition:\\n\\n1. **Chain of Thought (CoT)**: This technique encourages the model to \"think step by step,\" transforming large tasks into simpler, manageable steps, which also provides insight into the model\\'s reasoning process.\\n\\n2. **Tree of Thoughts**: This approach extends CoT by exploring multiple reasoning possibilities at each step. It decomposes the problem into various thought steps and generates multiple thoughts per step, creating a tree structure that can be searched using breadth-first or depth-first search methods.\\n\\n3. **Prompting**: Simple prompts can be used to guide the LLM in task decomposition, such as asking for the steps to achieve a goal or identifying subgoals.\\n\\n4. **Task-specific instructions**: Providing specific instructions tailored to the task, like asking for a story outline when writing a novel.\\n\\n5. **Human inputs**: Involving human guidance to assist in breaking down tasks.\\n\\nOverall, task decomposition is crucial for improving the efficiency and effectiveness of LLM agents in tackling complex problems.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RAG\n",
    "template = \"\"\"\n",
    "    Answer the following question based on this context:\n",
    "    {context}\n",
    "\n",
    "    Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "final_rag_chain = (\n",
    "    prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "final_rag_chain.invoke({\"context\": retrieved_docs_hyde, \"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2c3510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
