{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d657884b",
   "metadata": {},
   "source": [
    "## LangChain - Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7504cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9853be",
   "metadata": {},
   "source": [
    "### Logical routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f0ebe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route user query to the most relevant datasource\"\"\"\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        ..., \n",
    "        description=\"Given a user question choose which datasource would be the most relevant for answering their question\"\n",
    "    )\n",
    "\n",
    "# LLM with function call\n",
    "llm = AzureChatOpenAI(model=\"gpt-4o-mini\",api_version=\"2024-12-01-preview\")\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt\n",
    "system = \"\"\"\"\n",
    "    You are an expert at routing question to the appropriate data source\n",
    "    Based on the programming language the question is referring to, route\n",
    "    it to the relevant data source.\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router\n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfe561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"\"\n",
    "    Why doesn't the following code work:\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "    prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "    prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "result = router.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5cc5eff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RouteQuery(datasource='python_docs')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e2a1dd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_route(result):\n",
    "    match result.datasource.lower():\n",
    "        case \"python_docs\":\n",
    "            return \"chain for python_docs\"\n",
    "        \n",
    "        case \"js_docs\":\n",
    "            return \"chain for js_docs\"\n",
    "        \n",
    "        case \"golang_docs\":\n",
    "            return \"chain for golang_docs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d0b32421",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b5455582",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bcf42ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_result = full_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cf23c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for python_docs'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddd161a",
   "metadata": {},
   "source": [
    "### Semantical routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f998e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import AzureOpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfeec2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"\n",
    "    You are a very smart physics professor. \\\n",
    "    You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "    When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\n",
    "\"\"\"\n",
    "\n",
    "math_template = \"\"\"\n",
    "    You are a very good mathematician. You are great at answering math questions. \\\n",
    "    You are so good because you are able to break down hard problems into their component parts, \\\n",
    "    answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "    Here is a question:\n",
    "    {query}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ca4bd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed prompts\n",
    "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71b7aad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route question to prompt\n",
    "def prompt_router(input):\n",
    "    # Embed question\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # chosen prompt\n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5deb0c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9979f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A black hole is a region in space where the gravitational pull is so strong that nothing, not even light, can escape from it. This occurs when a massive star collapses under its own gravity at the end of its life cycle. The boundary surrounding a black hole is called the event horizon, and once an object crosses this threshold, it cannot return. Black holes can vary in size, from small \"stellar\" black holes formed by the collapse of individual stars to supermassive black holes, which are found at the centers of galaxies and can be millions or billions of times more massive than our Sun.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"What is a black hole?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
